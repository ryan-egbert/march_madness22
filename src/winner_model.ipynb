{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730e13bb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4def3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle as pck\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b3c2f",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "039b2605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/1391qbxd3jg3m15k2d19w9qw0000gn/T/ipykernel_25187/3970109353.py:1: DtypeWarning: Columns (8,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../input/input.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70d9bcf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>RECORD_PCT</th>\n",
       "      <th>PPG</th>\n",
       "      <th>FG%</th>\n",
       "      <th>FGAPG</th>\n",
       "      <th>OBPI</th>\n",
       "      <th>DBPI</th>\n",
       "      <th>SOR</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>OPP_TEAM</th>\n",
       "      <th>OPP_RECORD_PCT</th>\n",
       "      <th>OPP_PPG</th>\n",
       "      <th>OPP_FG%</th>\n",
       "      <th>OPP_FGAPG</th>\n",
       "      <th>OPP_OBPI</th>\n",
       "      <th>OPP_DBPI</th>\n",
       "      <th>OPP_SOR</th>\n",
       "      <th>OPP_SCORE</th>\n",
       "      <th>WINNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>74.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>54.647059</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>135</td>\n",
       "      <td>54</td>\n",
       "      <td>Texas Longhorns</td>\n",
       "      <td>0.816</td>\n",
       "      <td>75.6</td>\n",
       "      <td>45.3</td>\n",
       "      <td>59.970588</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Longhorns</td>\n",
       "      <td>0.816</td>\n",
       "      <td>75.6</td>\n",
       "      <td>45.3</td>\n",
       "      <td>59.970588</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>74.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>54.647059</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>135</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>74.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>54.647059</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>0.765</td>\n",
       "      <td>80.6</td>\n",
       "      <td>46.7</td>\n",
       "      <td>58.606061</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>0.765</td>\n",
       "      <td>80.6</td>\n",
       "      <td>46.7</td>\n",
       "      <td>58.606061</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>74.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>54.647059</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>74.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>54.647059</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>135</td>\n",
       "      <td>71</td>\n",
       "      <td>Belmont Bruins</td>\n",
       "      <td>0.735</td>\n",
       "      <td>80.1</td>\n",
       "      <td>45.2</td>\n",
       "      <td>61.181818</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>106</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TEAM  RECORD_PCT   PPG   FG%      FGAPG  OBPI  DBPI  SOR  \\\n",
       "0  Austin Peay Governors       0.686  74.6  45.1  54.647059   2.9  -1.8  135   \n",
       "1        Texas Longhorns       0.816  75.6  45.3  59.970588   9.4   4.3    7   \n",
       "2  Austin Peay Governors       0.686  74.6  45.1  54.647059   2.9  -1.8  135   \n",
       "3  Vanderbilt Commodores       0.765  80.6  46.7  58.606061  10.0  -1.6   26   \n",
       "4  Austin Peay Governors       0.686  74.6  45.1  54.647059   2.9  -1.8  135   \n",
       "\n",
       "  SCORE               OPP_TEAM  OPP_RECORD_PCT  OPP_PPG  OPP_FG%  OPP_FGAPG  \\\n",
       "0    54        Texas Longhorns           0.816     75.6     45.3  59.970588   \n",
       "1    74  Austin Peay Governors           0.686     74.6     45.1  54.647059   \n",
       "2    67  Vanderbilt Commodores           0.765     80.6     46.7  58.606061   \n",
       "3    81  Austin Peay Governors           0.686     74.6     45.1  54.647059   \n",
       "4    71         Belmont Bruins           0.735     80.1     45.2  61.181818   \n",
       "\n",
       "   OPP_OBPI  OPP_DBPI  OPP_SOR OPP_SCORE  WINNER  \n",
       "0       9.4       4.3        7        74       1  \n",
       "1       2.9      -1.8      135        54       0  \n",
       "2      10.0      -1.6       26        81       1  \n",
       "3       2.9      -1.8      135        67       0  \n",
       "4       6.8      -4.2      106        56       0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f371e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dd3e3",
   "metadata": {},
   "source": [
    "# Predict Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5a23009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/1391qbxd3jg3m15k2d19w9qw0000gn/T/ipykernel_25187/1678557736.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.SCORE = df.SCORE.apply(pd.to_numeric, errors=\"coerce\")\n",
      "/var/folders/3m/1391qbxd3jg3m15k2d19w9qw0000gn/T/ipykernel_25187/1678557736.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.OPP_SCORE = df.OPP_SCORE.apply(pd.to_numeric, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "df.SCORE = df.SCORE.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.OPP_SCORE = df.OPP_SCORE.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a10c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "      \"OPP_SCORE\", \n",
    "      \"SCORE\",\n",
    "      \"TEAM\",\n",
    "      \"OPP_TEAM\"])\n",
    "df = df.dropna()\n",
    "y = df.WINNER\n",
    "x = df.drop(columns=[\"WINNER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0df54301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.25, random_state=31523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ecd8e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    max_depth=25,\n",
    "    bootstrap=True)\n",
    "\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5a573680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE:   ==> 0.27284058332294653\n",
      "Random Forest        ==> 72.72\n"
     ]
    }
   ],
   "source": [
    "### Random Forest\n",
    "rf_pred = rf.predict(test_x)\n",
    "rf_acc = accuracy_score(test_y, rf_pred)\n",
    "rf_mae = mean_absolute_error(test_y, rf_pred)\n",
    "print(f\"{'Random Forest MAE:':<20} ==> {rf_mae}\")\n",
    "rf_predprob = rf.predict_proba(test_x)\n",
    "print(f\"{'Random Forest':<20} ==> {round(rf_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b720b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/regbert/rf/application/venv38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "log = LogisticRegression()\n",
    "log.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d63607e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression MAE: ==> 0.24507042253521127\n",
      "Logistic Regression  ==> 75.49\n"
     ]
    }
   ],
   "source": [
    "log_pred = log.predict(test_x)\n",
    "log_acc = accuracy_score(test_y, log_pred)\n",
    "log_mae = mean_absolute_error(test_y, log_pred)\n",
    "print(f\"{'Logistic Regression MAE:':<20} ==> {log_mae}\")\n",
    "log_predprob = log.predict_proba(test_x)\n",
    "print(f\"{'Logistic Regression':<20} ==> {round(log_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7a00f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 50, 10))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(10, 50, 10))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 50, 10))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ANN\n",
    "ann = MLPClassifier(hidden_layer_sizes = (10,50,10))\n",
    "ann.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9cd74811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net MAE:      ==> 0.24459678424529477\n",
      "Neural Net           ==> 75.54\n"
     ]
    }
   ],
   "source": [
    "### ANN\n",
    "ann_pred = ann.predict(test_x)\n",
    "ann_acc = accuracy_score(test_y, ann_pred)\n",
    "ann_mae = mean_absolute_error(test_y, ann_pred)\n",
    "print(f\"{'Neural Net MAE:':<20} ==> {ann_mae}\")\n",
    "ann_predprob = ann.predict_proba(test_x)\n",
    "print(f\"{'Neural Net':<20} ==> {round(ann_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6fb49",
   "metadata": {},
   "source": [
    "# Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a3b71e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ann_winner.pck\", 'wb') as f:\n",
    "    pck.dump(ann, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "740789ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_PCT</th>\n",
       "      <th>PPG</th>\n",
       "      <th>FG%</th>\n",
       "      <th>FGAPG</th>\n",
       "      <th>OBPI</th>\n",
       "      <th>DBPI</th>\n",
       "      <th>SOR</th>\n",
       "      <th>OPP_RECORD_PCT</th>\n",
       "      <th>OPP_PPG</th>\n",
       "      <th>OPP_FG%</th>\n",
       "      <th>OPP_FGAPG</th>\n",
       "      <th>OPP_OBPI</th>\n",
       "      <th>OPP_DBPI</th>\n",
       "      <th>OPP_SOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53540</th>\n",
       "      <td>0.657</td>\n",
       "      <td>77.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>111</td>\n",
       "      <td>0.657</td>\n",
       "      <td>66.9</td>\n",
       "      <td>43.3</td>\n",
       "      <td>54.906250</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100048</th>\n",
       "      <td>0.714</td>\n",
       "      <td>71.2</td>\n",
       "      <td>44.1</td>\n",
       "      <td>58.580645</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>85</td>\n",
       "      <td>0.865</td>\n",
       "      <td>76.3</td>\n",
       "      <td>47.6</td>\n",
       "      <td>55.088235</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130128</th>\n",
       "      <td>0.656</td>\n",
       "      <td>68.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>117</td>\n",
       "      <td>0.625</td>\n",
       "      <td>75.5</td>\n",
       "      <td>46.9</td>\n",
       "      <td>56.031250</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20855</th>\n",
       "      <td>0.367</td>\n",
       "      <td>67.7</td>\n",
       "      <td>43.3</td>\n",
       "      <td>53.300000</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>246</td>\n",
       "      <td>0.500</td>\n",
       "      <td>61.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>51.468750</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104210</th>\n",
       "      <td>0.267</td>\n",
       "      <td>61.5</td>\n",
       "      <td>44.9</td>\n",
       "      <td>51.400000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0.743</td>\n",
       "      <td>76.1</td>\n",
       "      <td>48.1</td>\n",
       "      <td>55.941176</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40649</th>\n",
       "      <td>0.344</td>\n",
       "      <td>62.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.093750</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>207</td>\n",
       "      <td>0.784</td>\n",
       "      <td>71.5</td>\n",
       "      <td>46.2</td>\n",
       "      <td>56.181818</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102076</th>\n",
       "      <td>0.516</td>\n",
       "      <td>72.3</td>\n",
       "      <td>44.1</td>\n",
       "      <td>59.600000</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>194</td>\n",
       "      <td>0.629</td>\n",
       "      <td>80.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121288</th>\n",
       "      <td>0.471</td>\n",
       "      <td>69.6</td>\n",
       "      <td>42.3</td>\n",
       "      <td>54.843750</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>265</td>\n",
       "      <td>0.276</td>\n",
       "      <td>61.2</td>\n",
       "      <td>41.5</td>\n",
       "      <td>49.724138</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157031</th>\n",
       "      <td>0.167</td>\n",
       "      <td>69.6</td>\n",
       "      <td>43.1</td>\n",
       "      <td>58.366667</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>327</td>\n",
       "      <td>0.194</td>\n",
       "      <td>70.3</td>\n",
       "      <td>40.5</td>\n",
       "      <td>58.903226</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132333</th>\n",
       "      <td>0.697</td>\n",
       "      <td>69.7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.727273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>96</td>\n",
       "      <td>0.438</td>\n",
       "      <td>67.1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>55.656250</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40115 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RECORD_PCT   PPG   FG%      FGAPG  OBPI  DBPI  SOR  OPP_RECORD_PCT  \\\n",
       "53540        0.657  77.0  45.0  59.000000   6.1  -3.7  111           0.657   \n",
       "100048       0.714  71.2  44.1  58.580645  -1.7   5.1   85           0.865   \n",
       "130128       0.656  68.7  49.7  50.500000   1.3   2.9  117           0.625   \n",
       "20855        0.367  67.7  43.3  53.300000  -1.3  -2.7  246           0.500   \n",
       "104210       0.267  61.5  44.9  51.400000  -6.0  -2.0  320           0.743   \n",
       "...            ...   ...   ...        ...   ...   ...  ...             ...   \n",
       "40649        0.344  62.2  40.0  54.093750  -5.0   2.7  207           0.784   \n",
       "102076       0.516  72.3  44.1  59.600000  -2.6   0.9  194           0.629   \n",
       "121288       0.471  69.6  42.3  54.843750  -4.3  -2.4  265           0.276   \n",
       "157031       0.167  69.6  43.1  58.366667  -4.8  -9.0  327           0.194   \n",
       "132333       0.697  69.7  45.0  56.727273   0.7   1.4   96           0.438   \n",
       "\n",
       "        OPP_PPG  OPP_FG%  OPP_FGAPG  OPP_OBPI  OPP_DBPI  OPP_SOR  \n",
       "53540      66.9     43.3  54.906250      -0.1       3.0      114  \n",
       "100048     76.3     47.6  55.088235       8.8       5.9        7  \n",
       "130128     75.5     46.9  56.031250       3.7      -0.5       98  \n",
       "20855      61.7     43.7  51.468750      -5.6       5.3      173  \n",
       "104210     76.1     48.1  55.941176       2.8       2.4       83  \n",
       "...         ...      ...        ...       ...       ...      ...  \n",
       "40649      71.5     46.2  56.181818       8.6       6.5       12  \n",
       "102076     80.5     45.5  61.500000       4.3      -3.2      113  \n",
       "121288     61.2     41.5  49.724138      -6.1      -2.7      308  \n",
       "157031     70.3     40.5  58.903226      -3.8      -9.2      334  \n",
       "132333     67.1     40.4  55.656250      -6.7      -1.8      315  \n",
       "\n",
       "[40115 rows x 14 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb668ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
