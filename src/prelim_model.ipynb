{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730e13bb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f4def3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b3c2f",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "039b2605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/1391qbxd3jg3m15k2d19w9qw0000gn/T/ipykernel_20721/3970109353.py:1: DtypeWarning: Columns (33,35,39,40,74,76,80,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../input/input.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "70d9bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>RECORD_PCT</th>\n",
       "      <th>WINS</th>\n",
       "      <th>LOSSES</th>\n",
       "      <th>CONF_PCT</th>\n",
       "      <th>CONF_WINS</th>\n",
       "      <th>CONF_LOSSES</th>\n",
       "      <th>HOME_PCT</th>\n",
       "      <th>HOME_WINS</th>\n",
       "      <th>HOME_LOSSES</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_SOR</th>\n",
       "      <th>OPP_SOR_SCURVE</th>\n",
       "      <th>OPP_SOS</th>\n",
       "      <th>OPP_NCSOS</th>\n",
       "      <th>OPP_QUAL_WINS</th>\n",
       "      <th>OPP_QUAL_LOSSES</th>\n",
       "      <th>OPP_QUALITY_INDICATOR</th>\n",
       "      <th>OPP_FINAL_STREAK</th>\n",
       "      <th>OPP_SCORE</th>\n",
       "      <th>WINNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0.686</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Longhorns</td>\n",
       "      <td>0.816</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0.816</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.816</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>60</td>\n",
       "      <td>269</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0.686</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>-2</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>0.765</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.765</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>60</td>\n",
       "      <td>269</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austin Peay Governors</td>\n",
       "      <td>0.686</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>0.686</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>59</td>\n",
       "      <td>275</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TEAM  RECORD_PCT  WINS  LOSSES  CONF_PCT  CONF_WINS  \\\n",
       "0  Austin Peay Governors       0.686    24      11     0.686       16.0   \n",
       "1        Texas Longhorns       0.816    31       7     0.816       13.0   \n",
       "2  Austin Peay Governors       0.686    24      11     0.686       16.0   \n",
       "3  Vanderbilt Commodores       0.765    26       8     0.765       10.0   \n",
       "4  Austin Peay Governors       0.686    24      11     0.686       16.0   \n",
       "\n",
       "   CONF_LOSSES  HOME_PCT  HOME_WINS  HOME_LOSSES  ...  OPP_SOR  \\\n",
       "0          4.0     0.686       12.0          1.0  ...        7   \n",
       "1          3.0     0.816       17.0          1.0  ...      135   \n",
       "2          4.0     0.686       12.0          1.0  ...       26   \n",
       "3          6.0     0.765       19.0          0.0  ...      135   \n",
       "4          4.0     0.686       12.0          1.0  ...      106   \n",
       "\n",
       "   OPP_SOR_SCURVE  OPP_SOS  OPP_NCSOS  OPP_QUAL_WINS OPP_QUAL_LOSSES  \\\n",
       "0               7       25         13             11               6   \n",
       "1              60      269        118              0               3   \n",
       "2              26       81        243              4               5   \n",
       "3              60      269        118              0               3   \n",
       "4              59      275        218              0               2   \n",
       "\n",
       "   OPP_QUALITY_INDICATOR  OPP_FINAL_STREAK  OPP_SCORE  WINNER  \n",
       "0               7.117647                -1         74       1  \n",
       "1               0.000000                -1         54       0  \n",
       "2               1.777778                -2         81       1  \n",
       "3               0.000000                -1         67       0  \n",
       "4               0.000000                -1         56       0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f371e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dd3e3",
   "metadata": {},
   "source": [
    "# Predict Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5a23009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NCSOS = df.NCSOS.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.OPP_NCSOS = df.OPP_NCSOS.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.FINAL_STREAK = df.FINAL_STREAK.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.OPP_FINAL_STREAK = df.OPP_FINAL_STREAK.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.SCORE = df.SCORE.apply(pd.to_numeric, errors=\"coerce\")\n",
    "df.OPP_SCORE = df.OPP_SCORE.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3c5f841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.CONF)\n",
    "df.CONF = le.transform(df.CONF)\n",
    "df.OPP_CONF = le.transform(df.OPP_CONF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3a10c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "#     \"OPP_SCORE\", \n",
    "#                       \"SCORE\",\n",
    "                      \"WINNER\",\n",
    "                      \"TEAM\",\n",
    "                      \"OPP_TEAM\",\n",
    "                      \"SOR_SCURVE\",\n",
    "                      \"OPP_SOR_SCURVE\",\n",
    "                      \"FINAL_STREAK\",\n",
    "                      \"OPP_FINAL_STREAK\"])\n",
    "# Drop columns that don't contrubute much to the predictions\n",
    "df = df.drop(columns=[\n",
    "    \"VS_AP_WINS\",\n",
    "    \"OPP_VS_AP_WINS\",\n",
    "    \"VS_AP_LOSSES\",\n",
    "    \"OPP_VS_AP_LOSSES\",\n",
    "    \"AWAY_WINS\",\n",
    "    \"OPP_AWAY_WINS\",\n",
    "    \"AWAY_LOSSES\",\n",
    "    \"OPP_AWAY_LOSSES\",\n",
    "    \"HOME_WINS\",\n",
    "    \"OPP_HOME_WINS\",\n",
    "    \"HOME_LOSSES\",\n",
    "    \"OPP_HOME_LOSSES\",\n",
    "    \"CONF\",\n",
    "    \"OPP_CONF\",\n",
    "    \"QUAL_WINS\",\n",
    "    \"QUAL_LOSSES\",\n",
    "    \"OPP_QUAL_WINS\",\n",
    "    \"OPP_QUAL_LOSSES\",\n",
    "    \"CONF_WINS\",\n",
    "    \"CONF_LOSSES\",\n",
    "    \"OPP_CONF_WINS\",\n",
    "    \"OPP_CONF_LOSSES\",\n",
    "])\n",
    "df = df.dropna()\n",
    "# y = df.WINNER\n",
    "y = df[[\"SCORE\", \"OPP_SCORE\"]]\n",
    "# y = pd.Dataframe({\"score\": df.SCORE, \"opp_score\": df.OPP_SCORE})\n",
    "# x = df.drop(columns=[\"WINNER\"])\n",
    "x = df.drop(columns=[\"SCORE\", \"OPP_SCORE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0df54301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ecd8e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/regbert/rf/application/venv38/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=1500,\n",
    "#     min_samples_leaf=4,\n",
    "#     max_features='auto',\n",
    "#     max_depth=50,\n",
    "#     bootstrap=True)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=1500,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='auto',\n",
    "    max_depth=50,\n",
    "    bootstrap=True\n",
    ")\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Log loss was the metric used in the Kaggle competition\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5a573680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest\n",
    "rf_pred = rf.predict(test_x)\n",
    "# rf_acc = accuracy_score(test_y, rf_pred)\n",
    "# rf_mae = mean_absolute_error(test_y, rf_pred)\n",
    "# print(f\"{'Random Forest MAE:':<20} ==> {rf_mae}\")\n",
    "# rf_predprob = rf.predict_proba(test_x)\n",
    "# print(f\"{'Random Forest':<20} ==> {round(rf_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b720b8fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (97489, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [270]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m log \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/utils/validation.py:1143\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1143\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (97489, 2) instead."
     ]
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d63607e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [271]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m log_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m log_acc \u001b[38;5;241m=\u001b[39m accuracy_score(test_y, log_pred)\n\u001b[1;32m      3\u001b[0m log_mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(test_y, log_pred)\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/rf/application/venv38/lib/python3.8/site-packages/sklearn/linear_model/_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "log_pred = log.predict(test_x)\n",
    "log_acc = accuracy_score(test_y, log_pred)\n",
    "log_mae = mean_absolute_error(test_y, log_pred)\n",
    "print(f\"{'Logistic Regression MAE:':<20} ==> {log_mae}\")\n",
    "log_predprob = log.predict_proba(test_x)\n",
    "print(f\"{'Logistic Regression':<20} ==> {round(log_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b7a00f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(50, 100, 25, 20))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(50, 100, 25, 20))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(50, 100, 25, 20))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ANN\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "# ann = MLPClassifier(hidden_layer_sizes = (50,100,25,20))\n",
    "ann = MLPRegressor(hidden_layer_sizes = (50,100,25,20))\n",
    "ann.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9cd74811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net MAE:      ==> 7.593390237583449\n"
     ]
    }
   ],
   "source": [
    "### ANN\n",
    "ann_pred = ann.predict(test_x)\n",
    "# ann_acc = accuracy_score(test_y, ann_pred)\n",
    "ann_mae = mean_absolute_error(test_y, ann_pred)\n",
    "print(f\"{'Neural Net MAE:':<20} ==> {ann_mae}\")\n",
    "# ann_predprob = ann.predict_proba(test_x)\n",
    "# print(f\"{'Neural Net':<20} ==> {round(ann_acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "603d6ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin = LinearRegression()\n",
    "lin.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "cdddfd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAE: ==> 7.5498096763301685\n",
      "Linear Regression (r-squared) ==> 0.40861809163776525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "lin_pred = lin.predict(test_x)\n",
    "lin_acc = lin.score(test_x, test_y)\n",
    "lin_mae = mean_absolute_error(test_y, lin_pred)\n",
    "print(f\"{'Linear Regression MAE:':<20} ==> {lin_mae}\")\n",
    "print(f\"{'Linear Regression (r-squared)':<20} ==> {lin_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fcf13a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.97505313, 71.17264902],\n",
       "       [69.64731666, 85.28729777],\n",
       "       [74.26335908, 57.37965378],\n",
       "       [71.51925209, 66.95508359],\n",
       "       [58.87390113, 70.40957209],\n",
       "       [74.41351676, 54.96028753],\n",
       "       [76.27560351, 75.26841313],\n",
       "       [73.79836661, 72.41906857],\n",
       "       [69.46529143, 57.50105662],\n",
       "       [74.11323436, 69.62829697]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a0c00b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_PCT</th>\n",
       "      <th>WINS</th>\n",
       "      <th>LOSSES</th>\n",
       "      <th>CONF_PCT</th>\n",
       "      <th>HOME_PCT</th>\n",
       "      <th>AWAY_PCT</th>\n",
       "      <th>PPG</th>\n",
       "      <th>ORBPG</th>\n",
       "      <th>DRBPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_FGAPG</th>\n",
       "      <th>OPP_FTAPG</th>\n",
       "      <th>OPP_3PAPG</th>\n",
       "      <th>OPP_OBPI</th>\n",
       "      <th>OPP_DBPI</th>\n",
       "      <th>OPP_BPIRK</th>\n",
       "      <th>OPP_SOR</th>\n",
       "      <th>OPP_SOS</th>\n",
       "      <th>OPP_NCSOS</th>\n",
       "      <th>OPP_QUALITY_INDICATOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>0.636</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.636</td>\n",
       "      <td>73.3</td>\n",
       "      <td>13.062500</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>54.781250</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>61</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18636</th>\n",
       "      <td>0.400</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>72.8</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>23.366667</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>59.781250</td>\n",
       "      <td>22.218750</td>\n",
       "      <td>14.968750</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87778</th>\n",
       "      <td>0.375</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>66.5</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>25.031250</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>56.064516</td>\n",
       "      <td>21.387097</td>\n",
       "      <td>18.967742</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>271</td>\n",
       "      <td>267</td>\n",
       "      <td>205</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135602</th>\n",
       "      <td>0.667</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>72.2</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>25.833333</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>57.205882</td>\n",
       "      <td>16.264706</td>\n",
       "      <td>23.911765</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>237</td>\n",
       "      <td>257</td>\n",
       "      <td>223</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20933</th>\n",
       "      <td>0.207</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.413793</td>\n",
       "      <td>23.448276</td>\n",
       "      <td>12.6</td>\n",
       "      <td>...</td>\n",
       "      <td>57.774194</td>\n",
       "      <td>22.838710</td>\n",
       "      <td>15.870968</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>139</td>\n",
       "      <td>136</td>\n",
       "      <td>182</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>0.484</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.484</td>\n",
       "      <td>64.6</td>\n",
       "      <td>10.838710</td>\n",
       "      <td>23.064516</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>54.928571</td>\n",
       "      <td>19.821429</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>333</td>\n",
       "      <td>311</td>\n",
       "      <td>338</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128010</th>\n",
       "      <td>0.632</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.632</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.441176</td>\n",
       "      <td>26.764706</td>\n",
       "      <td>15.2</td>\n",
       "      <td>...</td>\n",
       "      <td>57.314286</td>\n",
       "      <td>25.285714</td>\n",
       "      <td>16.857143</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>220</td>\n",
       "      <td>185</td>\n",
       "      <td>171</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128901</th>\n",
       "      <td>0.545</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.545</td>\n",
       "      <td>71.4</td>\n",
       "      <td>10.454545</td>\n",
       "      <td>27.303030</td>\n",
       "      <td>13.6</td>\n",
       "      <td>...</td>\n",
       "      <td>63.181818</td>\n",
       "      <td>20.121212</td>\n",
       "      <td>25.303030</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>258</td>\n",
       "      <td>236</td>\n",
       "      <td>234</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148889</th>\n",
       "      <td>0.688</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.688</td>\n",
       "      <td>66.1</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.966667</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>21.133333</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>225</td>\n",
       "      <td>210</td>\n",
       "      <td>123</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93241</th>\n",
       "      <td>0.676</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>71.8</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>29.121212</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>56.033333</td>\n",
       "      <td>24.966667</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>188</td>\n",
       "      <td>151</td>\n",
       "      <td>256</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RECORD_PCT  WINS  LOSSES  CONF_PCT  HOME_PCT  AWAY_PCT   PPG  \\\n",
       "99137        0.636    21      12     0.636     0.636     0.636  73.3   \n",
       "18636        0.400    12      18     0.400     0.400     0.400  72.8   \n",
       "87778        0.375    12      20     0.375     0.375     0.375  66.5   \n",
       "135602       0.667    20      10     0.667     0.667     0.667  72.2   \n",
       "20933        0.207     6      23     0.207     0.207     0.207  60.0   \n",
       "42950        0.484    15      16     0.484     0.484     0.484  64.6   \n",
       "128010       0.632    24      14     0.632     0.632     0.632  80.0   \n",
       "128901       0.545    18      15     0.545     0.545     0.545  71.4   \n",
       "148889       0.688    22      10     0.688     0.688     0.688  66.1   \n",
       "93241        0.676    23      11     0.676     0.676     0.676  71.8   \n",
       "\n",
       "            ORBPG      DRBPG   APG  ...  OPP_FGAPG  OPP_FTAPG  OPP_3PAPG  \\\n",
       "99137   13.062500  26.500000  12.3  ...  54.781250  23.343750  18.437500   \n",
       "18636   12.066667  23.366667  14.1  ...  59.781250  22.218750  14.968750   \n",
       "87778    9.687500  25.031250  12.2  ...  56.064516  21.387097  18.967742   \n",
       "135602  10.700000  25.833333  13.4  ...  57.205882  16.264706  23.911765   \n",
       "20933   11.413793  23.448276  12.6  ...  57.774194  22.838710  15.870968   \n",
       "42950   10.838710  23.064516  12.3  ...  54.928571  19.821429  16.750000   \n",
       "128010  12.441176  26.764706  15.2  ...  57.314286  25.285714  16.857143   \n",
       "128901  10.454545  27.303030  13.6  ...  63.181818  20.121212  25.303030   \n",
       "148889   8.400000  24.100000  14.0  ...  58.966667  15.366667  21.133333   \n",
       "93241   12.151515  29.121212  14.2  ...  56.033333  24.966667  23.666667   \n",
       "\n",
       "        OPP_OBPI  OPP_DBPI  OPP_BPIRK  OPP_SOR  OPP_SOS  OPP_NCSOS  \\\n",
       "99137        2.8       4.4         61       89       30       57.0   \n",
       "18636        3.7       0.2        101       97       82      274.0   \n",
       "87778       -4.6      -1.7        271      267      205      165.0   \n",
       "135602      -3.2      -0.8        237      257      223      109.0   \n",
       "20933        1.4       0.3        139      136      182       22.0   \n",
       "42950       -5.6      -7.6        333      311      338       99.0   \n",
       "128010      -3.9       0.8        220      185      171      202.0   \n",
       "128901      -3.3      -1.4        258      236      234      176.0   \n",
       "148889      -2.4      -0.4        225      210      123      278.0   \n",
       "93241        2.9      -4.1        188      151      256      237.0   \n",
       "\n",
       "        OPP_QUALITY_INDICATOR  \n",
       "99137                1.785714  \n",
       "18636                0.571429  \n",
       "87778                0.000000  \n",
       "135602               0.000000  \n",
       "20933                0.000000  \n",
       "42950                0.000000  \n",
       "128010               0.000000  \n",
       "128901               0.000000  \n",
       "148889               0.000000  \n",
       "93241                0.000000  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0cc23a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62., 59.],\n",
       "       [66., 75.],\n",
       "       [61., 43.],\n",
       "       [81., 71.],\n",
       "       [63., 79.],\n",
       "       [72., 63.],\n",
       "       [94., 85.],\n",
       "       [48., 58.],\n",
       "       [84., 57.],\n",
       "       [76., 63.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b90fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7fbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(df.columns[:-1])\n",
    "forest_importances = pd.Series(importances, index=feature_names).sort_values()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Variable Importances\")\n",
    "ax.set_ylabel(\"Impurity Decrease\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0762c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predicted_scores(predictions, actual_scores):\n",
    "    total_scores = len(predictions)\n",
    "    if total_scores != len(actual_scores):\n",
    "        print(\"Array lengths don't line up!\")\n",
    "        return -1\n",
    "    correct = 0\n",
    "    for i in range(total_scores):\n",
    "        pred = predictions[i]\n",
    "        score = actual_scores[i]\n",
    "        if pred[0] > pred[1] and score[0] > score[1] or \\\n",
    "            pred[0] < pred[1] and score[0] < score[1]:\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print(f\"Incorrect: Prediction({pred}) --> Score({score})\")\n",
    "            \n",
    "    return correct/total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c1c1d660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.747343371763837"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_predicted_scores(lin_pred, test_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "fe862ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7270340130472244"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_predicted_scores(rf_pred, test_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "df8a09a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552619702129405"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_predicted_scores(ann_pred, test_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a5341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
